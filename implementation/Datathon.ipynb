{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9eb4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "BASE_PATH = \"/Users/ananthu/AMRITA/Datathon_2025/Education_Dataset/\"\n",
    "\n",
    "FILES_2324 = {\n",
    "    \"facility\": BASE_PATH + \"100_fac.csv\",\n",
    "    \"teacher\": BASE_PATH + \"100_tch.csv\",\n",
    "    \"profile1\": BASE_PATH + \"100_prof1.csv\",\n",
    "    \"profile2\": BASE_PATH + \"100_prof2.csv\",\n",
    "    \"enrol1\": BASE_PATH + \"100_enr1.csv\",\n",
    "    \"enrol2\": BASE_PATH + \"100_enr2.csv\"\n",
    "}\n",
    "\n",
    "FILES_2425 = {\n",
    "    \"facility\": BASE_PATH + \"100_fac 2.csv\",\n",
    "    \"teacher\": BASE_PATH + \"100_tch 2.csv\",\n",
    "    \"profile1\": BASE_PATH + \"100_prof1 2.csv\",\n",
    "    \"profile2\": BASE_PATH + \"100_prof2 2.csv\",\n",
    "    \"enrol1\": BASE_PATH + \"100_enr1 2.csv\",\n",
    "    \"enrol2\": BASE_PATH + \"100_enr2 2.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af78404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_facility(df):\n",
    "    binary_cols = ['electricity_availability', 'internet', 'ict_lab_yn',\n",
    "                   'library_availability', 'playground_available', \n",
    "                   'handwash_facility_for_meal']\n",
    "    for col in binary_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace({1:1, 2:0, 3:0})\n",
    "    return df\n",
    "\n",
    "def clean_teacher(df):\n",
    "    cols_needed = ['pseudocode','total_tch','male','female']\n",
    "    return df[cols_needed].dropna(subset=['pseudocode'])\n",
    "\n",
    "def clean_profile(df):\n",
    "    cols_needed = ['pseudocode','state','district']\n",
    "    return df[cols_needed]\n",
    "\n",
    "def clean_enrolment(df):\n",
    "    df['total_students'] = df.filter(like='_b').sum(axis=1) + df.filter(like='_g').sum(axis=1)\n",
    "    df['boys_enrolled'] = df.filter(like='_b').sum(axis=1)\n",
    "    df['girls_enrolled'] = df.filter(like='_g').sum(axis=1)\n",
    "    return df[['pseudocode','total_students','boys_enrolled','girls_enrolled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4942bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_year(file_dict, year_label):\n",
    "    facility = clean_facility(pd.read_csv(file_dict[\"facility\"], low_memory=False))\n",
    "    teacher = clean_teacher(pd.read_csv(file_dict[\"teacher\"], low_memory=False))\n",
    "    profile1 = clean_profile(pd.read_csv(file_dict[\"profile1\"], low_memory=False))\n",
    "    enrolment = clean_enrolment(pd.read_csv(file_dict[\"enrol1\"], low_memory=False))\n",
    "\n",
    "    merged = facility.merge(teacher, on='pseudocode', how='left') \\\n",
    "                     .merge(enrolment, on='pseudocode', how='left') \\\n",
    "                     .merge(profile1, on='pseudocode', how='left')\n",
    "\n",
    "    district_df = merged.groupby(['state','district'], as_index=False).mean(numeric_only=True)\n",
    "    district_df['year'] = year_label\n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a60a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_indices(df):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    if 'laptop' in df.columns:\n",
    "        df['digital_device_avg'] = scaler.fit_transform(df[['laptop']].fillna(0))\n",
    "    elif 'desktop' in df.columns:\n",
    "        df['digital_device_avg'] = scaler.fit_transform(df[['desktop']].fillna(0))\n",
    "    else:\n",
    "        df['digital_device_avg'] = 0\n",
    "\n",
    "    def col(df, name_list):\n",
    "        for n in name_list:\n",
    "            if n in df.columns:\n",
    "                return df[n]\n",
    "        return pd.Series(0, index=df.index)\n",
    "\n",
    "    df['basic_infra_index'] = (\n",
    "        col(df, ['electricity_availability']) +\n",
    "        col(df, ['total_girls_func_toilet', 'total_boys_func_toilet'])/2 +\n",
    "        col(df, ['tap_fun_yn', 'pack_water_fun_yn', 'hand_pump_fun_yn'])/3 +\n",
    "        col(df, ['furniture_availability', 'furniture_availability_rate']) +\n",
    "        col(df, ['playground_available', 'playground_alt_yn'])\n",
    "    ) / 5\n",
    "\n",
    "    df['digital_infra_index'] = (\n",
    "        col(df, ['internet']) +\n",
    "        col(df, ['ict_lab_yn', 'comp_ict_lab_yn']) +\n",
    "        col(df, ['comp_lab_cond', 'computer_lab_condition']) +\n",
    "        col(df, ['smart_class_rate', 'smart_class_tv_tot']) +\n",
    "        df['digital_device_avg']\n",
    "    ) / 5\n",
    "\n",
    "    df['learning_env_index'] = (\n",
    "        col(df, ['library_availability']) +\n",
    "        col(df, ['handwash_facility_for_meal']) +\n",
    "        col(df, ['medical_checkups']) +\n",
    "        col(df, ['availability_ramps', 'ramps_availability_rate']) +\n",
    "        col(df, ['phy_lab_cond', 'chem_lab_cond', 'bio_lab_cond']).mean()\n",
    "    ) / 5\n",
    "\n",
    "    df['infrastructure_index'] = df[['basic_infra_index',\n",
    "                                     'digital_infra_index',\n",
    "                                     'learning_env_index']].mean(axis=1)\n",
    "\n",
    "    if 'total_tch' in df.columns:\n",
    "        df['PTR'] = df['total_students'] / df['total_tch']\n",
    "    else:\n",
    "        df['PTR'] = np.nan\n",
    "\n",
    "    if 'girls_enrolled' in df.columns and 'boys_enrolled' in df.columns:\n",
    "        df['GPI'] = df['girls_enrolled'] / df['boys_enrolled']\n",
    "    else:\n",
    "        df['GPI'] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8eddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retention and Dropout computed successfully.\n",
      "Rows: 1570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fp/w6yn5n6d4cb299k1w5hy5xgc0000gn/T/ipykernel_18100/2525095314.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.assign(Retention_Rate=(g['total_students'].pct_change()+1)*100))\n"
     ]
    }
   ],
   "source": [
    "df_2324 = process_year(FILES_2324, '2023-24')\n",
    "df_2425 = process_year(FILES_2425, '2024-25')\n",
    "\n",
    "df_2324 = compute_indices(df_2324)\n",
    "df_2425 = compute_indices(df_2425)\n",
    "\n",
    "combined = pd.concat([df_2324, df_2425], ignore_index=True)\n",
    "combined = combined.sort_values(['state', 'district', 'year'])\n",
    "\n",
    "combined = combined.drop_duplicates(subset=['state','district','year'], keep='first')\n",
    "\n",
    "retention = (\n",
    "    combined\n",
    "    .groupby(['state','district'], as_index=False, group_keys=False)\n",
    "    .apply(lambda g: g.assign(Retention_Rate=(g['total_students'].pct_change()+1)*100))\n",
    ")\n",
    "\n",
    "combined = retention.copy()\n",
    "\n",
    "combined['Dropout_Rate'] = 100 - combined['Retention_Rate']\n",
    "\n",
    "combined['Retention_Rate'] = combined['Retention_Rate'].fillna(100)\n",
    "combined['Dropout_Rate'] = combined['Dropout_Rate'].fillna(0)\n",
    "\n",
    "print(\"Retention and Dropout computed successfully.\")\n",
    "print(\"Rows:\", combined.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fce6110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GER, GPI, PTR and categories computed successfully.\n"
     ]
    }
   ],
   "source": [
    "combined['GER_primary'] = (combined['total_students'] / combined['total_students'].max()) * 100\n",
    "\n",
    "if {'girls_enrolled', 'boys_enrolled'}.issubset(combined.columns):\n",
    "    combined['GPI'] = combined['girls_enrolled'] / combined['boys_enrolled']\n",
    "else:\n",
    "    combined['GPI'] = np.nan\n",
    "\n",
    "def gpi_category(x):\n",
    "    if pd.isna(x): return \"Unknown\"\n",
    "    if 0.98 <= x <= 1.02: return \"Equal\"\n",
    "    elif x < 0.98: return \"Low Female Participation\"\n",
    "    else: return \"High Female Participation\"\n",
    "\n",
    "combined['GPI_Category'] = combined['GPI'].apply(gpi_category)\n",
    "\n",
    "if {'total_students', 'total_tch'}.issubset(combined.columns):\n",
    "    combined['PTR'] = combined['total_students'] / combined['total_tch']\n",
    "else:\n",
    "    combined['PTR'] = np.nan\n",
    "\n",
    "def ptr_category(x):\n",
    "    if pd.isna(x): return \"Unknown\"\n",
    "    if x <= 30: return \"Optimal\"\n",
    "    elif x <= 40: return \"Moderate\"\n",
    "    else: return \"Overcrowded\"\n",
    "\n",
    "combined['PTR_Category'] = combined['PTR'].apply(ptr_category)\n",
    "\n",
    "combined['GER_primary'] = combined['GER_primary'].fillna(0)\n",
    "combined['GPI'] = combined['GPI'].fillna(1)\n",
    "combined['PTR'] = combined['PTR'].fillna(35)\n",
    "\n",
    "print(\"GER, GPI, PTR and categories computed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec1ad0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average GER: 29.23\n",
      "Average GPI: 1.05\n",
      "Average PTR: 5.76\n",
      "\n",
      "Top 5 states by Infra Index:\n",
      "state\n",
      "CHANDIGARH     2.219382\n",
      "DELHI          1.818905\n",
      "LAKSHADWEEP    1.568100\n",
      "KERALA         1.566059\n",
      "PUDUCHERRY     1.543731\n",
      "Name: infrastructure_index, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAverage GER:\", round(combined['GER_primary'].mean(), 2))\n",
    "print(\"Average GPI:\", round(combined['GPI'].mean(), 2))\n",
    "print(\"Average PTR:\", round(combined['PTR'].mean(), 2))\n",
    "print(\"\\nTop 5 states by Infra Index:\")\n",
    "print(combined.groupby('state')['infrastructure_index'].mean().sort_values(ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afdee3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Tableau-ready file: /Users/ananthu/AMRITA/Datathon_2025/Education_Dataset/District_Level_Education_Infra_Final.csv\n",
      "Rows: 1570, Columns: 14\n",
      "\n",
      "=== DATA VALIDATION SUMMARY ===\n",
      "Average Infrastructure Index: 0.99\n",
      "Average GER: 29.23\n",
      "Average PTR: 5.76\n",
      "Average GPI: 1.05\n",
      "\n",
      "Retention & Dropout Check (first few rows):\n",
      "                       state                   district     year  \\\n",
      "0  ANDAMAN & NICOBAR ISLANDS                   ANDAMANS  2023-24   \n",
      "1  ANDAMAN & NICOBAR ISLANDS                   ANDAMANS  2024-25   \n",
      "2  ANDAMAN & NICOBAR ISLANDS  MIDDLE AND NORTH ANDAMANS  2023-24   \n",
      "3  ANDAMAN & NICOBAR ISLANDS  MIDDLE AND NORTH ANDAMANS  2024-25   \n",
      "4  ANDAMAN & NICOBAR ISLANDS                   NICOBARS  2023-24   \n",
      "5  ANDAMAN & NICOBAR ISLANDS                   NICOBARS  2024-25   \n",
      "6             ANDHRA PRADESH                 ANAKAPALLI  2023-24   \n",
      "7             ANDHRA PRADESH                 ANAKAPALLI  2024-25   \n",
      "8             ANDHRA PRADESH                  ANANTAPUR  2023-24   \n",
      "9             ANDHRA PRADESH                  ANANTAPUR  2024-25   \n",
      "\n",
      "   Retention_Rate  Dropout_Rate  \n",
      "0      100.000000      0.000000  \n",
      "1       95.941487      4.058513  \n",
      "2      100.000000      0.000000  \n",
      "3       93.303102      6.696898  \n",
      "4      100.000000      0.000000  \n",
      "5       95.920114      4.079886  \n",
      "6      100.000000      0.000000  \n",
      "7       96.188335      3.811665  \n",
      "8      100.000000      0.000000  \n",
      "9       99.136862      0.863138  \n"
     ]
    }
   ],
   "source": [
    "export_cols = [\n",
    "    'state','district','year',\n",
    "    'basic_infra_index','digital_infra_index','learning_env_index','infrastructure_index',\n",
    "    'GER_primary','GPI','GPI_Category','PTR','PTR_Category',\n",
    "    'Retention_Rate','Dropout_Rate'\n",
    "]\n",
    "\n",
    "export_cols = [c for c in export_cols if c in combined.columns]\n",
    "final_df = combined[export_cols].dropna(subset=['state','district']).reset_index(drop=True)\n",
    "\n",
    "final_df['infrastructure_index'] = final_df['infrastructure_index'].clip(0,1)\n",
    "final_df['GER_primary'] = final_df['GER_primary'].clip(0,150)\n",
    "final_df['GPI'] = final_df['GPI'].clip(0,2)\n",
    "final_df['PTR'] = final_df['PTR'].clip(0,80)\n",
    "final_df['Retention_Rate'] = final_df['Retention_Rate'].clip(0,150)\n",
    "final_df['Dropout_Rate'] = final_df['Dropout_Rate'].clip(-50,100)\n",
    "\n",
    "OUT_PATH = BASE_PATH + \"District_Level_Education_Infra_Final.csv\"\n",
    "final_df.to_csv(OUT_PATH, index=False)\n",
    "print(f\"Exported Tableau-ready file: {OUT_PATH}\")\n",
    "print(f\"Rows: {final_df.shape[0]}, Columns: {final_df.shape[1]}\")\n",
    "\n",
    "print(\"\\n=== DATA VALIDATION SUMMARY ===\")\n",
    "print(\"Average Infrastructure Index:\", round(final_df['infrastructure_index'].mean(), 3))\n",
    "print(\"Average GER:\", round(final_df['GER_primary'].mean(), 2))\n",
    "print(\"Average PTR:\", round(final_df['PTR'].mean(), 2))\n",
    "print(\"Average GPI:\", round(final_df['GPI'].mean(), 2))\n",
    "print(\"\\nRetention & Dropout Check (first few rows):\")\n",
    "print(final_df[['state','district','year','Retention_Rate','Dropout_Rate']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc8bbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing file successfully updated with growth % columns!\n",
      "Added columns: ['infra_growth_pct', 'digital_infra_growth_pct', 'GER_growth_pct', 'GPI_growth_pct', 'PTR_change_pct', 'Retention_change_pct']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/Users/ananthu/AMRITA/Datathon_2025/Education_Dataset/District_Level_Education_Infra_Final.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = df.sort_values(['state', 'year'])\n",
    "\n",
    "def add_yoy_growth(df, value_col, new_col):\n",
    "    df[new_col] = (\n",
    "        df.groupby('state')[value_col].pct_change() * 100\n",
    "    ).round(2)\n",
    "    return df\n",
    "\n",
    "df = (\n",
    "    df.pipe(add_yoy_growth, 'infrastructure_index', 'infra_growth_pct')\n",
    "      .pipe(add_yoy_growth, 'digital_infra_index', 'digital_infra_growth_pct')\n",
    "      .pipe(add_yoy_growth, 'GER_primary', 'GER_growth_pct')\n",
    "      .pipe(add_yoy_growth, 'GPI', 'GPI_growth_pct')\n",
    "      .pipe(add_yoy_growth, 'PTR', 'PTR_change_pct')\n",
    "      .pipe(add_yoy_growth, 'Retention_Rate', 'Retention_change_pct')\n",
    ")\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Existing file successfully updated with growth % columns!\")\n",
    "print(\"Added columns:\", \n",
    "      ['infra_growth_pct', 'digital_infra_growth_pct', \n",
    "       'GER_growth_pct', 'GPI_growth_pct', \n",
    "       'PTR_change_pct', 'Retention_change_pct'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
